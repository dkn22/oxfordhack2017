{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 270,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import requests\n",
    "import json \n",
    "import http.client, urllib.request, urllib.parse, urllib.error, base64\n",
    "import http\n",
    "import io\n",
    "import newspaper\n",
    "from multiprocessing import Pool\n",
    "from textblob import TextBlob\n",
    "import time "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 245,
   "metadata": {},
   "outputs": [],
   "source": [
    "api_key = \"bbc19a8158e147b79f964c7155272cb4\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 271,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "text finish\n",
      "-33.695647954940796\n"
     ]
    }
   ],
   "source": [
    "t = time.time()\n",
    "df = make_news_requ(sample_req)\n",
    "\n",
    "print(t-time.time())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 262,
   "metadata": {},
   "outputs": [],
   "source": [
    "sample_req = {'tree': \"everything\", \"sources\": [], 'sortBy': 'popularity', 'keywords': ['trump'],\"date\": \"\", \"to\":''}\n",
    "###final function which returns the entire dataframe with atributes\n",
    "def make_news_requ(input_dict):\n",
    "    base = 'https://newsapi.org/v2/'\n",
    "    tree = input_dict['tree']+ \"?\"\n",
    "    ###############\n",
    "    keywords = \"q=\"+ ',+'.join(input_dict['keywords'])\n",
    "    date = 'from=' + input_dict['date']\n",
    "    to = \"to=\" + input_dict['to']\n",
    "    sortBy = 'sortBy=popularity'\n",
    "    sources = \"sources=\" + ','.join(input_dict['sources'])\n",
    "    api_key = \"apiKey=bbc19a8158e147b79f964c7155272cb4\"\n",
    "    \n",
    "    add_on = \"\"\n",
    "    \n",
    "    for dic, ins in [[\"sources\", sources],[\"sortBy\", sortBy],[\"date\",date],['to',to]]:\n",
    "        if len(input_dict[dic]) !=0:\n",
    "            add_on += \"&\"+ins\n",
    "                               \n",
    "    url = base+tree+keywords + add_on + \"&\" +  api_key\n",
    "                                    \n",
    "    response = requests.get(url)\n",
    "    jsonified = json.loads(response.text)\n",
    "    \n",
    "    atr = jsonified['articles']\n",
    "    df = pd.DataFrame(columns = atr[0].keys())\n",
    "    #df = pd.DataFrame(atr[0])\n",
    "    for x in atr[1:]:\n",
    "        x['source'] = x['source']['name']\n",
    "        x['bias'] = article_text(x['url'])\n",
    "        df = df.append(x, ignore_index=True)\n",
    "    print(\"text finish\")\n",
    "    df['e_at_pic'] = df['urlToImage'].apply(func = emotion_fin)#pandas more inefficient use multithreading\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 275,
   "metadata": {},
   "outputs": [],
   "source": [
    "###creates a function which returns the emotions displayed on a picutre to a corresbonding art.\n",
    "def keywithmaxval(d): \n",
    "     v=list(d.values())\n",
    "     k=list(d.keys())\n",
    "     return k[v.index(max(v))]\n",
    "\n",
    "sattributes = ['age','glasses','smile', 'gender']\n",
    "maxattributes = ['emotion','facialHair']\n",
    "\n",
    "def add_to_df(instan):\n",
    "    if len(instan)  == 0:\n",
    "        return \"no faces\"\n",
    "    else:\n",
    "        facial_tempdic = {}\n",
    "\n",
    "        for attri in sattributes: \n",
    "            facial_tempdic[attri] =  instan[0]['faceAttributes'][attri]\n",
    "        for attri in maxattributes:\n",
    "            stats = instan[0]['faceAttributes'][attri]\n",
    "            facial_tempdic[attri] = keywithmaxval(stats) + \" \"+str(stats[keywithmaxval(stats)])\n",
    "        return facial_tempdic\n",
    "    \n",
    "def emotion_to_image(filename):\n",
    "    uri_base = 'https://westcentralus.api.cognitive.microsoft.com'\n",
    "    subscription_key = '4b5604997f8747448756700dfac8a51d'\n",
    "\n",
    "    headers = {\n",
    "    'Content-Type': 'application/octet-stream',\n",
    "    'Ocp-Apim-Subscription-Key': subscription_key,}\n",
    "\n",
    "    params = {\n",
    "   'returnFaceId': 'true', 'Adult': 'true',\n",
    "   'returnFaceLandmarks': 'false',\n",
    "   'returnFaceAttributes': 'age,gender,smile,facialHair,glasses,emotion,hair,makeup'}\n",
    "\n",
    "    path_to_face_api = '/face/v1.0/detect'\n",
    "    \n",
    "    with urllib.request.urlopen(filename) as url:\n",
    "        img_data = io.BytesIO(url.read())\n",
    "    try:\n",
    "        response = requests.post(uri_base + path_to_face_api,\n",
    "                                data=img_data,\n",
    "                                headers=headers,\n",
    "                                params=params)\n",
    "        parsed = response.json()\n",
    "        return(parsed)\n",
    "       \n",
    "    except Exception as e:\n",
    "        return([])\n",
    "    \n",
    "def emotion_fin(link):\n",
    "    try:\n",
    "        result = add_to_df(emotion_to_image(link))\n",
    "    except:\n",
    "        result = []\n",
    "    return result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 263,
   "metadata": {},
   "outputs": [],
   "source": [
    "###gives a sentiment for url\n",
    "def article_text(article_url):\n",
    "   try:\n",
    "       article = newspaper.Article(url=article_url, language='en')\n",
    "       article.download()\n",
    "       article.parse()\n",
    "       textb = TextBlob(article.text) \n",
    "       return textb.sentiment\n",
    "   except newspaper.ArticleException:\n",
    "       print(\"URL: %s not found\" % article_url)\n",
    "   return \"\"\n",
    "\n",
    "# def article_dict(urls):\n",
    "#    pool = Pool(len(urls))\n",
    "#    texts = pool.map(article_text, urls)\n",
    "#    if not len(texts) == len(urls):\n",
    "#        raise RuntimeError(\"article_dict(): Array sizes do not match !\")\n",
    "#    url_text_dict = {}\n",
    "#    for x in range(0, len(texts)):\n",
    "#        url_text_dict[urls[x]] = texts[x]\n",
    "#    return url_text_dict\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 214,
   "metadata": {},
   "outputs": [],
   "source": [
    "sample = {\"documents\":[{'id': 1, 'text': 'bad ugly shit'},{'id':2,\"text\": \"good well awesome fabulous\"}]}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 242,
   "metadata": {},
   "outputs": [],
   "source": [
    "haha = TextBlob(\"Trump could be better as his job\")"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 261,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Sentiment(polarity=0.07508672100468976, subjectivity=0.45208116319444436)"
      ]
     },
     "execution_count": 261,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "article_text('https://www.theroot.com/5-ways-white-people-can-fight-white-supremacy-1819286547')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 276,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'error': {'code': 'Unspecified',\n",
       "  'message': 'Access denied due to invalid subscription key. Make sure you are subscribed to an API you are trying to call and provide the right key.'}}"
      ]
     },
     "execution_count": 276,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "emotion_to_image(\"https://static.politico.com/dims4/default/fd0ac72/2147483647/resize/1160x%3E/quality/90/?url=https%3A%2F%2Fstatic.politico.com%2F2d%2F1c%2F7cf287c64bffbe597523c0e9cf69%2F171121-trump-gty-1160.jpg\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
